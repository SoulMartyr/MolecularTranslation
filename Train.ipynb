{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9c8f0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.cuda import amp\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "\n",
    "from net.Net import AmpNet\n",
    "from net.optim.Lookahead import Lookahead\n",
    "from net.optim.RAdam import RAdam\n",
    "from utils import Util, DataUtil\n",
    "import About\n",
    "version = About.version\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "out_dir = './checkpoint/v{}_weight'.format(version)\n",
    "\n",
    "image_size = 224\n",
    "vocab_size = 193\n",
    "max_length = 300\n",
    "\n",
    "learning_rate = 0.0001\n",
    "batch_size = 8\n",
    "epoch_num = 50000\n",
    "log_iteration = 1000\n",
    "valid_iteration = 5000\n",
    "save_iteration = 5000\n",
    "\n",
    "train_loss = torch.FloatTensor([0]).cuda().sum()\n",
    "valid_loss = torch.FloatTensor([0]).cuda().sum()\n",
    "train_accuracy = np.zeros(2, np.float32)\n",
    "valid_accuracy = np.zeros(2, np.float32)\n",
    "epoch_accuracy = np.zeros(2, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d981cc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle('./data/train_data.pkl')\n",
    "valid_data = pd.read_pickle('./data/valid_data.pkl')\n",
    "\n",
    "tokenizer = DataUtil.load_tokenizer()\n",
    "train_dataset = DataUtil.MolecularDataset(train_data, tokenizer)\n",
    "valid_dataset = DataUtil.MolecularDataset(valid_data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a4a907b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04:48:05 Load DataSet Success\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=RandomSampler(train_dataset),\n",
    "    batch_size=batch_size,\n",
    "    drop_last=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    collate_fn=DataUtil.collate_fn,\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    sampler=DataUtil.MolecularSampler(valid_dataset, 5000),\n",
    "    batch_size=batch_size,\n",
    "    drop_last=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    collate_fn=DataUtil.collate_fn,\n",
    ")\n",
    "\n",
    "Util.print_hint(\"Load DataSet Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03e274fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 2000\n",
      "04:48:06 Load Net Success\n"
     ]
    }
   ],
   "source": [
    "grad_scaler = amp.GradScaler()\n",
    "net = AmpNet().cuda()\n",
    "weight_path = \"D:/GraduationProject/MolecularTranslation/checkpoint/v1.0_weight/8epoch_2000iter.pth\"\n",
    "if weight_path is not None:\n",
    "    weight = torch.load(weight_path)\n",
    "    start_iteration = weight['iteration']\n",
    "    start_epoch = weight['epoch']\n",
    "    state_dict = weight['state_dict']\n",
    "    net.load_state_dict(state_dict, strict=False)\n",
    "    print(start_epoch,start_iteration)\n",
    "else:\n",
    "    start_iteration = 0\n",
    "    start_epoch = 0\n",
    "\n",
    "optimizer = Lookahead(RAdam(filter(lambda x: x.requires_grad, net.parameters()), lr=learning_rate), alpha=0.5, k=5)\n",
    "Util.print_hint(\"Load Net Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dfad21e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_num = 50000\n",
      "\n",
      "batch_size = 8\n",
      "\n",
      "|---------------Info----------------|------Train------|------Valid------|\n",
      "\n",
      "| time       epoch    iter   lr     | loss     dist   | loss     dist   |\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "\n",
      "[0.6602389812469482 None]\n",
      "[0.9926230907440186 None]\n",
      "[0.44927623867988586 None]\n",
      "[0.4577290117740631 None]\n",
      "[0.4108889102935791 None]\n",
      "[0.9489861726760864 None]\n",
      "[0.8456984758377075 None]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_12316\\2272165845.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     44\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     45\u001B[0m         \u001B[0mgrad_scaler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mscale\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_loss\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 46\u001B[1;33m         \u001B[0mgrad_scaler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     47\u001B[0m         \u001B[0mgrad_scaler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     48\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001B[0m in \u001B[0;36mstep\u001B[1;34m(self, optimizer, *args, **kwargs)\u001B[0m\n\u001B[0;32m    336\u001B[0m         \u001B[1;32massert\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moptimizer_state\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"found_inf_per_device\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"No inf checks were recorded for this optimizer.\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    337\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 338\u001B[1;33m         \u001B[0mretval\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_maybe_opt_step\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer_state\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    339\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    340\u001B[0m         \u001B[0moptimizer_state\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"stage\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mOptState\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSTEPPED\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001B[0m in \u001B[0;36m_maybe_opt_step\u001B[1;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001B[0m\n\u001B[0;32m    282\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_maybe_opt_step\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer_state\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    283\u001B[0m         \u001B[0mretval\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 284\u001B[1;33m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0msum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mv\u001B[0m \u001B[1;32min\u001B[0m \u001B[0moptimizer_state\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"found_inf_per_device\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    285\u001B[0m             \u001B[0mretval\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    286\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mretval\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001B[0m in \u001B[0;36m<genexpr>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    282\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_maybe_opt_step\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer_state\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    283\u001B[0m         \u001B[0mretval\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 284\u001B[1;33m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0msum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mv\u001B[0m \u001B[1;32min\u001B[0m \u001B[0moptimizer_state\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"found_inf_per_device\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    285\u001B[0m             \u001B[0mretval\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    286\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mretval\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "Util.print_msg_head(epoch_num, batch_size)\n",
    "iteration = start_iteration\n",
    "epoch = start_epoch\n",
    "rate = 0\n",
    "while epoch < epoch_num:\n",
    "    if epoch != start_epoch:\n",
    "        iteration = 0\n",
    "    for _, batch in enumerate(train_loader):\n",
    "        \n",
    "        if hasattr(torch.cuda, 'empty_cache'):\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        if iteration % save_iteration == 0 and iteration != start_iteration:\n",
    "            torch.save({\n",
    "                'iteration': iteration,\n",
    "                'epoch': epoch,\n",
    "                'state_dict': net.state_dict(),\n",
    "            }, out_dir + '/{}epoch_{}iter.pth'.format(epoch,iteration))\n",
    "        valid_accuracy = [None, None]\n",
    "        if iteration % valid_iteration == 0 and iteration != start_iteration:\n",
    "            valid_accuracy = DataUtil.valid(valid_loader, net)\n",
    "\n",
    "        batch_size = len(batch['index'])\n",
    "        image = batch['image'].cuda()\n",
    "        sequence = batch['sequence'].cuda()\n",
    "        length = batch['length']\n",
    "        net.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        with amp.autocast():\n",
    "            out = net(image, sequence)\n",
    "            train_loss = DataUtil.cross_entropy_loss_cuda(out, sequence,length)\n",
    "            # sequence = sequence.detach().cpu().numpy() \n",
    "            # predict = out.detach().cpu().numpy() .argmax(-1)\n",
    "            train_accuracy = np.array([train_loss.item(), None])\n",
    "        print(train_accuracy)\n",
    "        if iteration % log_iteration == 0 and iteration != start_iteration:\n",
    "            learning_rate = Util.get_learning_rate(optimizer)\n",
    "            Util.print_flush()\n",
    "            Util.print_msg(epoch, iteration, learning_rate, train_accuracy, valid_accuracy, save_iteration)\n",
    "\n",
    "\n",
    "        grad_scaler.scale(train_loss).backward()\n",
    "        grad_scaler.step(optimizer)\n",
    "        grad_scaler.update()\n",
    "\n",
    "        iteration += 1\n",
    "    epoch += 1\n",
    "    Util.print_flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b21110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd923da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f75c546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}