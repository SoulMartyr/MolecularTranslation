{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9c8f0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.cuda import amp\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "\n",
    "from net.Net import AmpNet\n",
    "from net.optim.Lookahead import Lookahead\n",
    "from net.optim.RAdam import RAdam\n",
    "from utils import Util, DataUtil\n",
    "import About\n",
    "version = About.version\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "out_dir = '../result/v{}'.format(version)\n",
    "\n",
    "image_size = 224\n",
    "vocab_size = 193\n",
    "max_length = 300\n",
    "\n",
    "learning_rate = 0.0001\n",
    "batch_size = s\n",
    "epoch_num = 1\n",
    "log_iteration = 1000\n",
    "valid_iteration = 5000\n",
    "save_iteration = 5000\n",
    "\n",
    "train_loss = torch.FloatTensor([0]).cuda().sum()\n",
    "valid_loss = torch.FloatTensor([0]).cuda().sum()\n",
    "train_accuracy = np.zeros(2, np.float32)\n",
    "valid_accuracy = np.zeros(2, np.float32)\n",
    "epoch_accuracy = np.zeros(2, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d981cc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle('./data/train_data.pkl')\n",
    "valid_data = pd.read_pickle('./data/valid_data.pkl')\n",
    "\n",
    "tokenizer = DataUtil.load_tokenizer()\n",
    "train_dataset = DataUtil.MolecularDataset(train_data, tokenizer)\n",
    "valid_dataset = DataUtil.MolecularDataset(valid_data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a4a907b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03:43:49 Load DataSet Success\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=RandomSampler(train_dataset),\n",
    "    batch_size=batch_size,\n",
    "    drop_last=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    collate_fn=DataUtil.collate_fn,\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    sampler=DataUtil.MolecularSampler(valid_dataset, 5000),\n",
    "    batch_size=batch_size,\n",
    "    drop_last=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    collate_fn=DataUtil.collate_fn,\n",
    ")\n",
    "\n",
    "Util.print_hint(\"Load DataSet Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03e274fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03:43:50 Load Net Success\n"
     ]
    }
   ],
   "source": [
    "grad_scaler = amp.GradScaler()\n",
    "net = AmpNet().cuda()\n",
    "weight_path = None\n",
    "# if weight_path is not None:\n",
    "#     weight = torch.load(weight_path, map_location=lambda storage, loc: storage)\n",
    "#     start_iteration = weight['iteration']\n",
    "#     start_epoch = weight['epoch']\n",
    "#     state_dict = weight['state_dict']\n",
    "#     net.load_state_dict(state_dict, strict=False)\n",
    "# else:\n",
    "start_iteration = 0\n",
    "start_epoch = 0\n",
    "\n",
    "optimizer = Lookahead(RAdam(filter(lambda x: x.requires_grad, net.parameters()), lr=learning_rate), alpha=0.5, k=5)\n",
    "Util.print_hint(\"Load Net Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dfad21e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_num = 1\n",
      "\n",
      "batch_size = 8\n",
      "\n",
      "|---------------Info----------------|------Train------|------Valid------|\n",
      "\n",
      "| time       epoch    iter   lr     | loss     dist   | loss     dist   |\n",
      "\n",
      " -------------------------------------------------------------- \n",
      "\n",
      "1\n",
      "2\n",
      "[  6.92509747 523.25      ]\n",
      "vaild [6.799323, 709.1875]\n",
      "1\n",
      "2\n",
      "[  6.82040405 602.875     ]\n",
      "vaild [6.7933908, 662.0]\n",
      "1\n",
      "2\n",
      "[  6.78371525 533.875     ]\n",
      "vaild [6.791613, 692.625]\n",
      "1\n",
      "2\n",
      "[  6.67319298 396.5       ]\n",
      "vaild [6.621893, 674.8125]\n",
      "1\n",
      "2\n",
      "[  6.7340498 677.5      ]\n",
      "vaild [6.625881, 673.0]\n",
      "1\n",
      "2\n",
      "[  6.44932556 367.875     ]\n",
      "vaild [6.3301272, 661.1875]\n",
      "1\n",
      "2\n",
      "[  6.01779366 497.625     ]\n",
      "vaild [5.948336, 627.0625]\n",
      "1\n",
      "2\n",
      "[  5.6791029 421.25     ]\n",
      "vaild [5.519314, 548.125]\n",
      "1\n",
      "2\n",
      "[  6.00776958 413.        ]\n",
      "vaild [5.8563294, 612.8125]\n",
      "1\n",
      "2\n",
      "[  5.41725063 201.875     ]\n",
      "vaild [5.344402, 480.5]\n",
      "1\n",
      "2\n",
      "[  5.33491039 328.125     ]\n",
      "vaild [5.076963, 321.8125]\n",
      "1\n",
      "2\n",
      "[  5.25699759 281.        ]\n",
      "vaild [5.223693, 282.875]\n",
      "1\n",
      "2\n",
      "[  5.3306036 278.5      ]\n",
      "vaild [5.328002, 281.1875]\n",
      "1\n",
      "2\n",
      "[  5.11350012 342.5       ]\n",
      "vaild [4.944716, 348.5]\n",
      "1\n",
      "2\n",
      "[  4.97441387 280.375     ]\n",
      "vaild [4.7651935, 324.3125]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10948\\1722194628.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'index'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0msequence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sequence'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'length'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Util.print_msg_head(epoch_num, batch_size)\n",
    "iteration = start_iteration\n",
    "epoch = start_epoch\n",
    "rate = 0\n",
    "while epoch < epoch_num:\n",
    "    for _, batch in enumerate(train_loader):\n",
    "        \n",
    "        if hasattr(torch.cuda, 'empty_cache'):\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        if iteration % save_iteration == 0 and iteration != start_iteration:\n",
    "            torch.save({\n",
    "                'iteration': iteration,\n",
    "                'epoch': epoch,\n",
    "                'state_dict': net.state_dict(),\n",
    "            }, out_dir + '/weight/{}iter.pth'.format(iteration))\n",
    "        valid_accuracy = [None, None]\n",
    "        if iteration % valid_iteration == 0 and iteration != start_iteration:\n",
    "            valid_accuracy = DataUtil.valid(valid_loader, net)\n",
    "\n",
    "        batch_size = len(batch['index'])\n",
    "        image = batch['image'].cuda()\n",
    "        sequence = batch['sequence'].cuda()\n",
    "        length = batch['length']\n",
    "        net.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        with amp.autocast():\n",
    "            out = net(image, sequence)\n",
    "            train_loss = DataUtil.cross_entropy_loss_cuda(out, sequence,length)\n",
    "            sequence = sequence.detach().cpu().numpy() \n",
    "            predict = out.detach().cpu().numpy() .argmax(-1)\n",
    "            train_accuracy = np.array([train_loss.item(), DataUtil.calculate_edit_distance(predict, sequence,tokenizer)])\n",
    "\n",
    "\n",
    "        if iteration % log_iteration == 0 and iteration != start_iteration:\n",
    "            learning_rate = Util.get_learning_rate(optimizer)\n",
    "            Util.print_flush()\n",
    "            Util.print_msg(epoch, iteration, learning_rate, train_accuracy, valid_accuracy, save_iteration)\n",
    "\n",
    "        epoch_accuracy += train_accuracy\n",
    "        \n",
    "        print(train_accuracy)\n",
    "        print('vaild',valid_accuracy)\n",
    "        grad_scaler.scale(train_loss).backward()\n",
    "        grad_scaler.step(optimizer)\n",
    "        grad_scaler.update()\n",
    "\n",
    "    if iteration % log_iteration == 0:\n",
    "        Util.print_epoch(log_iteration, epoch_accuracy[0] / 100, epoch_accuracy[1] / 100)\n",
    "        epoch_accuracy[...] = 0\n",
    "    iteration += 1\n",
    "epoch += 1\n",
    "Util.print_flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b21110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd923da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f75c546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "woniu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
