{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from Util import spilt_formula_layer,spilt_other_layers\n",
    "import pandas as pd\n",
    "tqdm.pandas(desc='apply')\n",
    "\n",
    "data_dir = \"../data\"\n",
    "data = pd.read_csv(data_dir + '/molecular-translation/train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "apply: 100%|██████████████████████████████████████████████████████████████| 2424186/2424186 [01:08<00:00, 35175.71it/s]\n",
      "apply: 100%|███████████████████████████████████████████████████████████████| 2424186/2424186 [08:44<00:00, 4620.59it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab = set()\n",
    "data.InChI.progress_apply(lambda x: vocab.update(spilt_formula_layer(x.split('/')[1]).split(' ')))\n",
    "data.InChI.progress_apply(lambda x: vocab.update(spilt_other_layers(x.split('/')[2:]).strip().split(' ')))\n",
    "key = sorted(list(vocab))\n",
    "key.extend(['<sos>','<eos>','<pad>'])\n",
    "value = range(len(key))\n",
    "word_dict = dict(zip(key,value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'(': 0, ')': 1, '+': 2, ',': 3, '-': 4, '/b': 5, '/c': 6, '/h': 7, '/i': 8, '/m': 9, '/s': 10, '/t': 11, '0': 12, '1': 13, '10': 14, '100': 15, '101': 16, '102': 17, '103': 18, '104': 19, '105': 20, '106': 21, '107': 22, '108': 23, '109': 24, '11': 25, '110': 26, '111': 27, '112': 28, '113': 29, '114': 30, '115': 31, '116': 32, '117': 33, '118': 34, '119': 35, '12': 36, '120': 37, '121': 38, '122': 39, '123': 40, '124': 41, '125': 42, '126': 43, '127': 44, '128': 45, '129': 46, '13': 47, '130': 48, '131': 49, '132': 50, '133': 51, '134': 52, '135': 53, '136': 54, '137': 55, '138': 56, '139': 57, '14': 58, '140': 59, '141': 60, '142': 61, '143': 62, '144': 63, '145': 64, '146': 65, '147': 66, '148': 67, '149': 68, '15': 69, '150': 70, '151': 71, '152': 72, '153': 73, '154': 74, '155': 75, '156': 76, '157': 77, '158': 78, '159': 79, '16': 80, '161': 81, '163': 82, '165': 83, '167': 84, '17': 85, '18': 86, '19': 87, '2': 88, '20': 89, '21': 90, '22': 91, '23': 92, '24': 93, '25': 94, '26': 95, '27': 96, '28': 97, '29': 98, '3': 99, '30': 100, '31': 101, '32': 102, '33': 103, '34': 104, '35': 105, '36': 106, '37': 107, '38': 108, '39': 109, '4': 110, '40': 111, '41': 112, '42': 113, '43': 114, '44': 115, '45': 116, '46': 117, '47': 118, '48': 119, '49': 120, '5': 121, '50': 122, '51': 123, '52': 124, '53': 125, '54': 126, '55': 127, '56': 128, '57': 129, '58': 130, '59': 131, '6': 132, '60': 133, '61': 134, '62': 135, '63': 136, '64': 137, '65': 138, '66': 139, '67': 140, '68': 141, '69': 142, '7': 143, '70': 144, '71': 145, '72': 146, '73': 147, '74': 148, '75': 149, '76': 150, '77': 151, '78': 152, '79': 153, '8': 154, '80': 155, '81': 156, '82': 157, '83': 158, '84': 159, '85': 160, '86': 161, '87': 162, '88': 163, '89': 164, '9': 165, '90': 166, '91': 167, '92': 168, '93': 169, '94': 170, '95': 171, '96': 172, '97': 173, '98': 174, '99': 175, 'B': 176, 'Br': 177, 'C': 178, 'Cl': 179, 'D': 180, 'F': 181, 'H': 182, 'I': 183, 'N': 184, 'O': 185, 'P': 186, 'S': 187, 'Si': 188, 'T': 189, '<sos>': 190, '<eos>': 191, '<pad>': 192}\n"
     ]
    }
   ],
   "source": [
    "print(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir+'/tokenizer_word_dict.pickle', 'wb') as f:\n",
    "    pickle.dump(word_dict, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Vocab Size is 193\n",
      "Load Tokenizer Success.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "apply: 100%|█████████████████████████████████████████████████████████████| 2424186/2424186 [00:05<00:00, 468401.24it/s]\n",
      "apply: 100%|██████████████████████████████████████████████████████████████| 2424186/2424186 [00:47<00:00, 51396.88it/s]\n",
      "apply: 100%|███████████████████████████████████████████████████████████████| 2424186/2424186 [07:46<00:00, 5201.92it/s]\n",
      "apply: 100%|██████████████████████████████████████████████████████████████| 2424186/2424186 [01:15<00:00, 32321.20it/s]\n",
      "apply: 100%|█████████████████████████████████████████████████████████████| 2424186/2424186 [00:04<00:00, 516309.01it/s]\n"
     ]
    }
   ],
   "source": [
    "from DataUtil import generate_train_data,generate_test_data\n",
    "\n",
    "generate_train_data()\n",
    "generate_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "apply: 100%|███████████████████████████████████████████████████████████████| 2020155/2020155 [08:04<00:00, 4165.96it/s]\n",
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "apply: 100%|█████████████████████████████████████████████████████████████████| 404031/404031 [01:34<00:00, 4263.97it/s]\n",
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "apply: 100%|█████████████████████████████████████████████████████████████| 1616107/1616107 [00:05<00:00, 297895.71it/s]\n"
     ]
    }
   ],
   "source": [
    "vaild_fold = 5\n",
    "data = pd.read_csv(data_dir+'/train_data.csv')\n",
    "test_data = pd.read_csv(data_dir+'/test_data.csv')\n",
    "\n",
    "train_data = data[data.fold != vaild_fold]\n",
    "vaild_data = data[data.fold == vaild_fold]\n",
    "train_data['sequence'] = train_data.sequence.progress_apply(lambda x:eval(x))\n",
    "vaild_data['sequence'] = vaild_data.sequence.progress_apply(lambda x:eval(x))\n",
    "test_data['sequence'] = test_data.sequence.progress_apply(lambda x: [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_pickle('../data/train_data.pkl')\n",
    "vaild_data.to_pickle('../data/vaild_data.pkl')\n",
    "test_data.to_pickle('../data/test_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'cuda'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24200\\3911910278.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/train_data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sequence'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'cuda'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(data_dir+'/train_data.csv')\n",
    "print(type(data['sequence'][0].cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
